# ğŸ›¡ï¸ LLM Evaluation & Guardrails Dashboard

<p align="center">
  <img width="800" alt="Guardrails Dashboard" src="https://github.com/user-attachments/assets/9b1b9a51-47d4-4393-91e3-421b53ff2096" />

</p>

<p align="center">
  <strong>Production-ready LLM evaluation toolkit with CLI tool and real-time monitoring dashboard</strong>
</p>

<p align="center">
  <a href="#-features">Features</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-demo">Demo</a> â€¢
  <a href="#-technical-highlights">Technical Details</a>
</p>

---

## ğŸ¯ **Project Overview**

This project delivers a comprehensive solution for **LLM safety evaluation and monitoring** in production environments. Built with enterprise-grade reliability and developer experience in mind, it combines a powerful CLI tool with real-time web monitoring.

### **Problem Solved**
- **Safety Monitoring**: Track LLM outputs for toxicity, PII leaks, and policy violations
- **Performance Evaluation**: Measure latency, accuracy, and token usage across models
- **Production Readiness**: Policy-driven guardrails with automated blocking and reporting
- **Local-First**: No external dependencies or API costs - runs entirely on your infrastructure

### **Key Achievements**
- âœ… **Zero-dependency evaluation** - Works completely offline after setup
- âœ… **Enterprise-grade monitoring** - Real-time dashboard with policy enforcement
- âœ… **Production reliability** - Graceful degradation and comprehensive error handling
- âœ… **Developer experience** - Rich CLI with progress bars, colored output, and detailed reports

---

## ğŸš€ **Features**

### **CLI Evaluation Tool**
- ğŸ  **Local-First**: Integrates with Ollama for offline LLM inference
- ğŸ“Š **Comprehensive Metrics**: Latency, accuracy, toxicity, PII detection, token counting
- ğŸ›¡ï¸ **Policy Enforcement**: Configurable thresholds with automated violation blocking
- ğŸ“ˆ **Rich Reporting**: JSON, CSV, and Markdown outputs with detailed failure analysis
- ğŸ§ª **Extensible Architecture**: Clean provider interface for future LLM integrations

### **Real-Time Dashboard**
- ğŸ“± **Web Interface**: Modern, responsive dashboard for monitoring evaluation results
- ğŸ”„ **Live Updates**: Auto-refreshing metrics and violation tracking
- ğŸ“¡ **REST APIs**: Programmatic access to evaluation data and statistics
- ğŸ¯ **Production Ready**: Single-file deployment with zero external dependencies

---

## ğŸƒâ€â™‚ï¸ **Quick Start**

### **Prerequisites**
```bash
# Install Ollama (https://ollama.ai/)
curl -fsSL https://ollama.ai/install.sh | sh

# Pull a model
ollama pull llama3

# Verify setup
ollama run llama3 \"Hello world\"
```

### **Installation & Usage**
```bash
# Clone repository
git clone https://github.com/AdamsCode1/llm-evals-guardrails-dashboard.git
cd llm-evals-guardrails-dashboard

# Setup CLI tool
cd llm-evals-cli
python -m venv .venv && source .venv/bin/activate
pip install typer[all] requests pydantic pandas rich tabulate

# Run evaluation
python -m evals.cli run --model llama3 --prompts prompts.csv --policy policy.json

# Start monitoring dashboard
cd ../guardrails-dashboard
python3 dashboard.py
# â†’ Open http://localhost:8080
```

### **Live Dashboard**
The screenshot above shows the dashboard displaying real evaluation data:
- **2 evaluation runs** completed successfully
- **10 total evaluations** across different prompts
- **100% accuracy rate** (all prompts matched expected patterns)
- **4.6s average latency** (typical for local Ollama inference)
- **30% violation rate** (demonstrates safety monitoring in action)

---

## ğŸ—ï¸ **Architecture**

### **System Design**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI Tool      â”‚    â”‚   Evaluation     â”‚    â”‚   Dashboard     â”‚
â”‚                 â”‚    â”‚   Pipeline       â”‚    â”‚                 â”‚
â”‚ â€¢ Typer CLI     â”‚â”€â”€â”€â–¶â”‚ â€¢ Provider APIs  â”‚â”€â”€â”€â–¶â”‚ â€¢ HTTP Server   â”‚
â”‚ â€¢ Rich Output   â”‚    â”‚ â€¢ Safety Metrics â”‚    â”‚ â€¢ REST APIs     â”‚
â”‚ â€¢ Progress Bars â”‚    â”‚ â€¢ Policy Engine  â”‚    â”‚ â€¢ Real-time UI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Data Storage   â”‚
                       â”‚                  â”‚
                       â”‚ â€¢ JSONL Results  â”‚
                       â”‚ â€¢ CSV Reports    â”‚
                       â”‚ â€¢ Markdown Docs  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Core Components**

| Component | Purpose | Technology Stack |
|-----------|---------|------------------|
| **CLI Interface** | User interaction & orchestration | Python, Typer, Rich |
| **Provider Layer** | LLM API integration | HTTP clients, async patterns |
| **Metrics Engine** | Safety & performance analysis | Detoxify, Presidio, regex |
| **Policy Engine** | Threshold enforcement | Pydantic validation |
| **Reporting** | Multi-format output generation | Pandas, tabulate |
| **Dashboard** | Real-time monitoring | HTTP server, responsive HTML |

---

## ğŸ¬ **Demo**

### **CLI Workflow**
```bash
# Environment check
python -m evals.cli check --model llama3
âœ… Ollama provider available
âœ… Model llama3 accessible
âœ… Core dependencies installed

# Run evaluation
python -m evals.cli run --model llama3 --prompts prompts.csv
Evaluating â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 5/5 prompts
âœ… Evaluation complete: runs/20250805-215941
ğŸ“Š Results: 5 prompts, 100% accuracy, 1 blocked

# Generate report
python -m evals.cli report runs/20250805-215941
ğŸ“„ Report generated: runs/20250805-215941/report.md
```

### **Dashboard Features**
- **Real-time metrics**: Live updates from evaluation runs
- **Policy violations**: Track and analyze safety failures
- **Performance monitoring**: Latency and token usage trends
- **Historical data**: Browse past evaluation results

---

## ğŸ”§ **Technical Highlights**

### **Engineering Excellence**
- **Type Safety**: Full Pydantic models with runtime validation
- **Error Handling**: Graceful degradation for optional dependencies
- **Testing**: 34+ unit tests with pytest covering core functionality
- **Code Quality**: Ruff linting and formatting, clean architecture patterns
- **Documentation**: Comprehensive README with examples and troubleshooting

### **Production Features**
- **Dependency Isolation**: Core vs optional feature separation
- **Graceful Degradation**: Works even without advanced safety features
- **Performance Optimization**: Streaming responses and timeout handling
- **Monitoring**: Rich CLI feedback and detailed logging
- **Scalability**: Clean provider interface for multi-LLM support

### **Key Technical Decisions**
1. **Local-First Architecture**: No external API dependencies or costs
2. **Modular Design**: Separation of concerns with clean interfaces
3. **Progressive Enhancement**: Core functionality works, safety features are optional
4. **Developer Experience**: Rich CLI with progress indicators and colored output
5. **Data Portability**: Multiple output formats (JSON, CSV, Markdown)

### **Deployment Options**
- **Development**: Local Python environment with pip
- **Production**: Docker containerization ready
- **CI/CD**: GitHub Actions compatible testing and deployment
- **Enterprise**: Air-gapped environments supported

---

## ğŸ“ **Project Structure**

```
llm-evals-guardrails-dashboard/
â”œâ”€â”€ llm-evals-cli/              # CLI evaluation tool
â”‚   â”œâ”€â”€ evals/                  # Core Python package
â”‚   â”‚   â”œâ”€â”€ cli.py             # Typer CLI interface
â”‚   â”‚   â”œâ”€â”€ providers.py       # LLM provider integrations
â”‚   â”‚   â”œâ”€â”€ metrics.py         # Safety metrics (toxicity, PII)
â”‚   â”‚   â”œâ”€â”€ policy.py          # Policy validation engine
â”‚   â”‚   â”œâ”€â”€ run.py             # Evaluation orchestrator
â”‚   â”‚   â””â”€â”€ report.py          # Multi-format reporting
â”‚   â”œâ”€â”€ tests/                 # Unit test suite (34+ tests)
â”‚   â”œâ”€â”€ runs/                  # Generated evaluation results
â”‚   â”œâ”€â”€ prompts.csv            # Sample evaluation prompts
â”‚   â”œâ”€â”€ policy.json            # Default safety policy
â”‚   â””â”€â”€ README.md              # Detailed CLI documentation
â””â”€â”€ guardrails-dashboard/       # Web monitoring interface
    â”œâ”€â”€ dashboard.py           # Single-file HTTP server
    â”œâ”€â”€ demo.py               # Usage examples
    â””â”€â”€ Makefile              # Build automation
```

---

## ğŸš¦ **Usage Examples**

### **Basic Evaluation**
```bash
python -m evals.cli run --model llama3 --prompts prompts.csv
```

### **Custom Policy**
```json
{
  \"max_latency_ms\": 5000,
  \"require_accuracy\": true,
  \"enable_toxicity\": true,
  \"toxicity_threshold\": 0.3,
  \"enable_pii\": true
}
```

### **API Integration**
```bash
# Get evaluation statistics
curl http://localhost:8080/api/stats

# List recent runs
curl http://localhost:8080/api/runs

# Check violations
curl http://localhost:8080/api/violations
```

---

## ğŸ“ **Learning Outcomes**

This project demonstrates proficiency in:

### **Backend Development**
- **Python Architecture**: Clean package design with proper separation of concerns
- **API Design**: REST endpoints with proper error handling and status codes
- **CLI Development**: Professional command-line tools with rich user experience
- **Data Processing**: Pandas integration for CSV/JSONL data handling

### **DevOps & Reliability**
- **Dependency Management**: Graceful degradation and optional feature handling
- **Testing Strategy**: Comprehensive unit test coverage with pytest
- **Error Handling**: Production-grade exception management
- **Documentation**: Professional README with setup and troubleshooting guides

### **Product Engineering**
- **User Experience**: Progress bars, colored output, and intuitive commands
- **Monitoring**: Real-time dashboards with auto-refresh capabilities
- **Configuration**: JSON-based policy management with validation
- **Scalability**: Extensible provider interface for future enhancements

---

## ğŸ“Š **Performance Metrics**

| Metric | Value | Description |
|--------|-------|-------------|
| **Test Coverage** | 34+ tests | Comprehensive unit test suite |
| **Response Time** | ~4.6s avg | Local inference with Ollama |
| **Accuracy Rate** | 100% | Regex pattern matching validation |
| **Safety Detection** | 30% violation rate | Policy-based blocking |
| **Dependencies** | Minimal core | 6 core packages, optional safety features |

---

## ğŸ¤ **Contributing**

This project welcomes contributions! Here's how to get started:

1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature/amazing-feature`
3. **Run** tests: `pytest -q`
4. **Commit** changes: `git commit -m 'Add amazing feature'`
5. **Push** to branch: `git push origin feature/amazing-feature`
6. **Submit** a Pull Request

---

## ğŸ“„ **License**

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ”— **Links**

- **Live Demo**: [Dashboard Screenshot](#-project-overview)
- **Documentation**: [CLI README](llm-evals-cli/README.md)
- **Technical Details**: [Engineering Guide](docs/ENGINEERING.md)
- **Metrics Framework**: [Evaluation Metrics](docs/METRICS.md)
- **Issues**: [GitHub Issues](https://github.com/AdamsCode1/llm-evals-guardrails-dashboard/issues)
- **Ollama**: [https://ollama.ai/](https://ollama.ai/)

---

<p align=\"center\">
  <strong>Built with â¤ï¸ for production LLM safety and monitoring</strong>
</p>

<p align=\"center\">
  No external APIs â€¢ No subscription costs â€¢ Local-first architecture
</p>
